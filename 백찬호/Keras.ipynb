{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f42d707-a4b8-489e-ab88-9209c14a0b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51f3670a-6951-4539-92d7-1ac5344e1ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f3009f4-1c65-49bd-94e4-145d75ab47c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff501dd8-14c8-4c23-b3c2-6692755f817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "network.add(layers.Dense(10, activation='softmax')) #10개의 확률점수가 들어있는 배열, 2번째 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40ce76e6-e74e-41da-88ff-663bed038867",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4396ce9-f11a-4882-a114-af2b0e4eb18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "test_images = test_images.reshape((10000,28*28))\n",
    "test_images = test_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5fa851d-a91e-4b34-9bda-e35f88930329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b0f250c-ccbb-4ef4-9b68-556e54da8778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.2538 - accuracy: 0.9265\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.1039 - accuracy: 0.9691\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0685 - accuracy: 0.9796\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9856 ETA: 1s - loss: 0.0484 - ac - 8s 131us/step - loss: 0.0494 - accuracy: 0.9856\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0369 - accuracy: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x14d3a1317f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f4bc039-adaf-42a8-825a-3f99fa5d8be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 47us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eb154f9-9163-4a4f-9a8b-4863a9552abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.9811000227928162\n"
     ]
    }
   ],
   "source": [
    "print('test_acc:',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb12353-c0fa-4641-ab5a-6aca12835946",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\User\\anaconda3\\envs\\ai\\lib\\site-packages\\keras\\datasets\\imdb.py:101: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\User\\anaconda3\\envs\\ai\\lib\\site-packages\\keras\\datasets\\imdb.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels)=imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e56f785-a384-42a6-b960-69768b65f956",
   "metadata": {},
   "source": [
    "train_labels와 test_labels는 부정을 나타내는 0과 긍정을 나타내는 1의 리스트이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09072e83-7bab-489d-b6c7-64860cfd974b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad6b9064-76e8-4d6b-9b41-2977b4f8feef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9687f4f-3e8e-4979-bcd7-3d3a81a2ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6828c3fc-bc66-4af4-9eea-6d0d1a02034b",
   "metadata": {},
   "source": [
    "리스트를 텐서로 바꾸는 방법\n",
    "* 같은 길이가 되도록 리스트에 패딩(padding)을 추가하고 (samples, sequence_length)크기의 정수텐서로 변환한다. 그 다음 이 정수텐서를 다룰 수 있는 층을 신경망의 첫 번째 층으로 사용한다\n",
    "\n",
    "* 리스트를 원 핫 인코딩(one-hot encoding)해서 0과 1의 벡터로 변환한다. 예를 들어 시퀀스[3, 5]를 인덱스 3과 5의 위치는 1이고 그 외는 모두 0인 10000차원의 벡터로 각각 변환한 후 부동소수 벡터데이터를 다룰 수 있는 Dense층을 신경망의 첫 번째 층으로 사용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ffb40c6-8d90-4ffc-bfa5-65817fbafc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 원 핫 벡터로 만들기(두번째 방식)\n",
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "  results = np.zeros((len(sequences), dimension))\n",
    "  for i, sequence in enumerate(sequences):\n",
    "    results[i, sequence] = 1.\n",
    "  return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "771937dc-514c-4b26-92ee-59aff8200f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00c7b3cc-0e23-45f0-ac24-5172772f13ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation = 'relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation = 'relu'))\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20c4f9e8-e0d9-44d5-8f49-5db7abd208f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1609187c-cb37-4536-b361-98a9a82d8caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
